\subsection{Initial Object Detection}
As the intelligence hierarchy demonstrates, the first component of our model needed to be able to detect when an apple appeared in the drone's field of view. 
We trained a lightweight convolutional neural network (CNN), that was based off of MobileNet~\cite{Sandler2018,PyTorchMobileNet} in order to accomplish this. 
In order to do this, we selected a Haar-Cascade model because of its lightweight nature, simplicity, and its real-time object detection capabilities.\footnote{The Haar-Cascade model was trained using a graphical user interface created by Amin Ahmadi (\url{https://amin-ahmadi.com/cascade-trainer-gui/}).} 
The data we used to train the model was a compilation of data sets such as the Fruit360 data set \cite{Fruit360}.
In addition to the positive images (images containing apples), a myriad of negative images (images without apples) were used to train the model.
The negative images were were selected based on specific characteristics we knew the model would eventually encounter. 
For example, we have a set of images that contain peoples hands and hands holding objects that aren't apples, so that the model can differentiate between when someone is holding an apple and when someone is holding a different object.
Anther set of images that we included in the negative training data featured different kinds of trees that didn't have apples in them.
These trees ranged from trees that were structurally similar to apple trees, but didn't contain any apples, to trees that contained different kinds of fruit, like oranges.
This was done with the express purpose of extensibility.
As the goal is to eventually introduce our model to an orchard, the drone will need to be familiar with what a tree with or without apples looks like.
Although we experienced a decent amount of success using this model, we lacked the data, training time, and compute capacity to 