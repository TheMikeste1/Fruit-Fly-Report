\section{Results}
\subsection{Model Performance}\label{subsec:model-performance}
Overall, the models developed as part of the intelligence hierarchy performed fairly well.
\autoref{fig:apple-tree-mode-training-curve} demonstrates a learning curve for one of the first-layer apple-in-view models.


\begin{figure}[!htb]
    \centering
    \includegraphics[width=\columnwidth,keepaspectratio]
    {./figures/mobile_model_apple_trees_16its_2022-11-15_training_curve}
    \caption{
        Learning curve for a apple-in-view CNN.
        The model is a retrained version of MobileNet~\cite{Sandler2018,PyTorchMobileNet}, which is a more light-weight while still very powerful CNN.
        Loss is in mean squared error.
    }
    \label{fig:apple-tree-mode-training-curve}
\end{figure}


\begin{figure}[!htb]
    \centering
    \includegraphics[width=\columnwidth,keepaspectratio]
    {./figures/confusion_matrix_All_Files_on_Dataset}
    \caption{
        The confusion matrix of the primary apple-in-view detection model.
        The column is the predicted label, while the row is the true label.
        A perfect model will have 0s in the top-right and bottom-left corner.
    }
    \label{fig:apple-in-view-confusion-matrix}
\end{figure}



\subsection{Robot Performance}\label{subsec:robot-performance}
\begin{figure}[!htb]
    \centering
    \includegraphics[width=\columnwidth,keepaspectratio]
    {./figures/haar-cascade-detection}
    \caption{
        An image taken through the drone camera during the calculate-relative-position phase of the intelligence hierarchy.
        A Haar-Cascade model is used to identify the apple's location and distance relative to the drone, after which the drone is able to approach the apple.
    }
    \label{fig:drone-haar-cascade}
\end{figure}
