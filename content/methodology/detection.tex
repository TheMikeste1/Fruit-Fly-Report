\subsection{Initial Object \& Location Detection}\label{subsec:initial-object
-&-location-detection}
As the intelligence hierarchy demonstrates, the first component of our model needed
to be able to detect when an apple appeared in the drone's field of view.
We trained a lightweight convolutional neural network (CNN), that was based off of
MobileNet~\cite{Sandler2018,PyTorchMobileNet} in order to accomplish this.
In order to do this, we selected a Haar-Cascade model because of its lightweight
nature, simplicity, and its real-time object detection capabilities.\footnote{The
Haar-Cascade model was trained using a graphical user interface created by Amin
Ahmadi (\url{https://amin-ahmadi.com/cascade-trainer-gui/}).}
The data we used to train the model was a compilation of datasets such as the
Fruit360 dataset ~\cite{Fruit360}.
In addition to the positive images (images containing apples), a myriad of negative
images (images without apples) were used to train the model.
The negative images were selected based on specific characteristics we knew the model
would eventually encounter.
For example, we have a set of images that contain hands holding objects that aren't
apples, so that the model can differentiate between when someone
is holding an apple and when someone is holding a different object.
Another set of images that we included in the negative training data featured
different kinds of trees that didn't have apples in them.
These trees ranged from trees that were structurally similar to apple trees, but
didn't contain any apples, to trees that contained different kinds of fruit, like
oranges.
This was done with the express purpose of extensibility.
As the goal is to eventually introduce our model to an orchard, the drone will need
to be familiar with what a tree with or without apples looks like.
This helps ensure that the model will be effective when it enters into a production
environment.
